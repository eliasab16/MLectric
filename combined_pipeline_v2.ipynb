{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "q38Bz1zGle25"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNxdDoxVxyHbQNVnDJQRzpI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eliasab16/MLectric/blob/main/combined_pipeline_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "352VXlPDyCN4",
        "outputId": "aa6cb667-d40f-4706-b42c-c82b02a3010c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/Othercomputers/My MacBook Pro/tf-od/panels\n"
          ]
        }
      ],
      "source": [
        "# prompt: mount google drive and load a keras model model\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd drive/Othercomputers/My\\ MacBook\\ Pro/tf-od/panels/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "metadata": {
        "id": "RndxyMqKcBvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install poppler-utils -y\n",
        "!pip install pdf2image"
      ],
      "metadata": {
        "id": "pzmdz_fq0zsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pdf2image\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "4JviUG7vzBzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.name=='posix':\n",
        "    !apt-get install protobuf-compiler -y\n",
        "    !cd models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install ."
      ],
      "metadata": {
        "id": "GVa8Tlt7TKOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ],
      "metadata": {
        "id": "oig4t5N2S60V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSIFIER_PATH = os.path.join('workspace/classifier')\n",
        "\n",
        "CUSTOM_MODEL_NAME = 'faster_rcnn'\n",
        "PRETRAINED_MODEL_NAME = 'faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'\n",
        "\n",
        "paths = {\n",
        "    'TRAINED_CLASSIFIERS': os.path.join(CLASSIFIER_PATH, 'trained_models'),\n",
        "    'WORKSPACE_PATH': os.path.join('workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('models'),\n",
        "    'ANNOTATION_PATH': os.path.join('workspace','annotated'),\n",
        "    'IMAGE_PATH': os.path.join('workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('workspace','models',CUSTOM_MODEL_NAME),\n",
        "    'OUTPUT_PATH': os.path.join('workspace','models',CUSTOM_MODEL_NAME, 'export'),\n",
        "    'TFJS_PATH':os.path.join('workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'),\n",
        "    'TFLITE_PATH':os.path.join('workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'),\n",
        "    'PROTOC_PATH':os.path.join('protoc')\n",
        "}\n",
        "\n",
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME),\n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ],
      "metadata": {
        "id": "p7AhUhZDy-j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "XwNuRADZlrvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {\n",
        "    0: 'm3x6', 1: 'm3x10', 2: 'm3x16', 3: 'm3x20', 4: 'm3x25', 5: 'm3x32', 6: 'm3x40', 7: 'm3x50', 8: 'm3x63',\n",
        "    9: 'm1x6', 10: 'm1x10', 11: 'm1x16', 12: 'm1x20', 13: 'm1x32', 14: 'af12', 15: 'af16', 16: 'af26', 17: 'aff',\n",
        "    18: 'bhaat2x40', 19: 'bhaat4x40', 20: 'b3x40', 21: 'b3x63', 22: 'b3x80', 23: 'b3x100', 24: 'b3x125',\n",
        "    25: 'b3x160', 26: 'b3x250', 27: 'b3x320'\n",
        "}\n",
        "\n",
        "excluded_labels = {\n",
        "    28: 'sr', 29: 'clock', 30: 'ms', 31: 'm1x+N'\n",
        "}\n",
        "\n",
        "hebrew_labels = {\n",
        "    0: '3x6 מא״ז', 1: '3x10 מא״ז', 2: '3x16 מא״ז', 3: '3x20 מא״ז', 4: '3x25 מא״ז', 5: '3x32 מא״ז', 6: '3x40 מא״', 7: '3x50מא״ז ', 8: '3x63 מא״ז',\n",
        "    9: '1x6 מא״ז', 10: '1x10 מא״ז', 11: '1x16 מא״ז', 12: '1x20 מא״ז', 13: '1x32 מא״ז', 14: 'AF12 מגען', 15: 'AF16 מגען', 16: 'AF26 מגען', 17: 'AFF מגען',\n",
        "    18: '2x40 פחת', 19: '4x40 פחת', 20: '3x40 מפסק', 21: '3x63 מפסק', 22: '3x80 מפסק', 23: '3x100 מפסק', 24: '3x125 מפסק',\n",
        "    25: '3x160 מפסק', 26: '3x250 מפסק', 27: '3x320 מפסק', 28: 'מגע עזר SR', 29: 'שעון', 30: 'MS הגנת מנוע', 31: '1x+N מא״ז'\n",
        "}"
      ],
      "metadata": {
        "id": "htIHm9E_rMg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "from cv2 import imread\n",
        "\n",
        "def pdfToImages(pdf_path):\n",
        "    img_array = []\n",
        "    images = convert_from_path(pdf_path, 500)\n",
        "\n",
        "    for img in images:\n",
        "      img_array.append(np.array(img))\n",
        "\n",
        "    return img_array"
      ],
      "metadata": {
        "id": "OHP0p1mhlrLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load models"
      ],
      "metadata": {
        "id": "lEBGNuUhzgbp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Detection model"
      ],
      "metadata": {
        "id": "QEK3OoJLz3sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-34')).expect_partial()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJ2L1501d8a3",
        "outputId": "355f6148-416b-445e-aa2d-fd75fe32147d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7b188ec09d50>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ],
      "metadata": {
        "id": "7sY7NfZ6d2iB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mapping excluded class to main label\n",
        "excluded_classes = {4: 28, 7: 29, 8: 30, 9: 31}"
      ],
      "metadata": {
        "id": "EGGzZo8ofcaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detectFromImages(images, detection_threshold=0.9):\n",
        "  detection_boxes = set() # (detection box array, image index)\n",
        "\n",
        "  for image_ind, image_np in enumerate(images):\n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    detections = detect_fn(input_tensor)\n",
        "\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                  for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    label_id_offset = 1\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64) + label_id_offset\n",
        "\n",
        "    # filter categories\n",
        "    for detection_index, score in enumerate(detections['detection_scores']):\n",
        "      if score >= detection_threshold:\n",
        "        class_id = detections['detection_classes'][detection_index]\n",
        "\n",
        "        if class_id not in excluded_classes:\n",
        "          # convert to tuple so that it can be hashed and stored in a set\n",
        "          box_coord_tuple = tuple(detections['detection_boxes'][detection_index])\n",
        "          detection_boxes.add((box_coord_tuple, image_ind))\n",
        "        else:\n",
        "          # convert excluded class id to main label id\n",
        "          detected_classes[excluded_classes[class_id]] += 1\n",
        "\n",
        "  return detection_boxes"
      ],
      "metadata": {
        "id": "wztJIVCpzelZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display image\n",
        "    # plt.figure(figsize=(14, 10))\n",
        "    # image_np_with_detections = image_np.copy()\n",
        "\n",
        "    # viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "    #             image_np_with_detections,\n",
        "    #             detections['detection_boxes'],\n",
        "    #             detections['detection_classes'],\n",
        "    #             detections['detection_scores'],\n",
        "    #             category_index,\n",
        "    #             use_normalized_coordinates=True,\n",
        "    #             max_boxes_to_draw=30,\n",
        "    #             min_score_thresh=.9,\n",
        "    #             line_thickness=2,\n",
        "    #             agnostic_mode=False)\n",
        "\n",
        "    # plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "    # plt.show()"
      ],
      "metadata": {
        "id": "XHRe8--xDA9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Classifier model"
      ],
      "metadata": {
        "id": "rFyGuQQYz1HL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = load_model(os.path.join(paths['TRAINED_CLASSIFIERS'], 'alexnet78.h5'))"
      ],
      "metadata": {
        "id": "4MVfHzupyxAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.models.save_model(classifier, './deployment/classifier')"
      ],
      "metadata": {
        "id": "VxZURTWBdgXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorflowjs_converter --input_format=keras_saved_model ./deployment/classifier ./deployment/classifier/classifier_tfjs"
      ],
      "metadata": {
        "id": "yiFQjY1OfASZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine models"
      ],
      "metadata": {
        "id": "Tn4fMAS6xOo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = 'workspace/images/raw_data/full_pdf/schematic-1.pdf'"
      ],
      "metadata": {
        "id": "l7fV9Vr-xWJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
      ],
      "metadata": {
        "id": "_4vzyE8pxjKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "detected_classes = {}\n",
        "for i in range(1, 32):\n",
        "    detected_classes[i] = 0\n",
        "\n",
        "images = pdfToImages(pdf_path)\n",
        "\n",
        "boxes = detectFromImages(images, 0.9)\n",
        "\n",
        "for box, image_index in boxes:\n",
        "  box = np.array(box) # box is a tuple of 4 entries (coordinates)\n",
        "  full_image = images[image_index]\n",
        "\n",
        "  image_height = full_image.shape[0]\n",
        "  image_width = full_image.shape[1]\n",
        "\n",
        "  roi = box*[image_height, image_width, image_height, image_width]\n",
        "  region = full_image[int(0.99*roi[0]):int(1.01*roi[2]), int(0.99*roi[1]):int(1.01*roi[3])]\n",
        "\n",
        "  plt.imshow(region)\n",
        "\n",
        "  # resize to match the input size of the classifier\n",
        "  region = cv2.resize(region, (256, 256))\n",
        "  new_region = np.expand_dims(region, axis=0)\n",
        "  new_region = classifier.predict(new_region, verbose=False)\n",
        "\n",
        "  prediction = np.argmax(new_region)\n",
        "\n",
        "  print(f'{hebrew_labels[prediction]}, image: {image_index}')\n",
        "  plt.show()\n",
        "  print('_________')\n",
        "\n",
        "  detected_classes[prediction] += 1\n",
        "\n",
        "\n",
        "# display results\n",
        "for class_id in detected_classes:\n",
        "  if detected_classes[class_id] > 0:\n",
        "    print(f'{hebrew_labels[class_id]}:')\n",
        "    print(f'{detected_classes[class_id]}')\n",
        "    print('________')\n"
      ],
      "metadata": {
        "id": "vNB_-KDeFTHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimentation code"
      ],
      "metadata": {
        "id": "q38Bz1zGle25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "height = images[1].shape[0]\n",
        "width = images[1].shape[1]"
      ],
      "metadata": {
        "id": "VqLroCDN-xD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roi = det[3]*[height, width, height, width]\n",
        "region = images[1][int(0.99*roi[0]):int(1.01*roi[2]), int(0.99*roi[1]):int(1.01*roi[3])]\n",
        "plt.imshow(region)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7kUz7xDb_Id2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "region.shape"
      ],
      "metadata": {
        "id": "QUXiRM-IFj_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(ind):\n",
        "  height = images[ind].shape[0]\n",
        "  width = images[ind].shape[1]\n",
        "  roi_np = dets[ind][0]\n",
        "  image_ind = dets[ind][1]\n",
        "\n",
        "  roi = roi_np*[height, width, height, width]\n",
        "  region = images[image_ind][int(0.99*roi[0]):int(1.01*roi[2]), int(0.99*roi[1]):int(1.01*roi[3])]\n",
        "  plt.imshow(region)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "a7g7Ct-lB2qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2_zFWPIhDFzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1OjiUB6t4Unx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}